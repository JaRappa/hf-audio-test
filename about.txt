.\aws-hf-audio-test\Scripts\activate


📁 Project Structure
/home/jake/hf-test/
├── app.py              # Main Flask server with AI pipeline
├── requirements.txt    # All Python dependencies
├── setup.sh           # Automated setup script for Arch Linux
├── server.sh           # Server management script
├── test_setup.py       # System testing script
├── README.md           # Complete documentation
└── templates/
    └── index.html      # Beautiful web UI

quickstart
1. install everything
./setup.sh
2. test the setup
./server.sh test
3. start the server
./server.sh start
4. find server IP
./server.sh ip
5. Access from any device on your LAN: Open browser to http://[server-ip]:5000

🔧 Features
AI Pipeline:

Speech-to-Text: Whisper model for accurate transcription
Text Generation: DialoGPT for conversational AI responses
Text-to-Speech: Coqui TTS for natural voice synthesis
Web Interface:

Beautiful, modern UI with audio visualization
Real-time audio recording with WebRTC
File upload support for audio files
Live status updates and error handling
Responsive design for mobile/desktop
Server Management:

Easy setup script for Arch Linux
System testing and health checks
Systemd service integration
Comprehensive logging and monitoring
🌐 Usage
From the Web UI:

Click "Start Recording" and speak
Or upload an audio file
View transcription, AI response, and hear the audio reply
API Endpoints:

GET /health - Server health check
POST /process_audio - Process audio through pipeline
⚙️ System Requirements
Minimum: 4GB RAM, 5GB storage, 2+ CPU cores Recommended: 8GB+ RAM, SSD storage, GPU (optional)

The system will automatically detect and use CUDA if available for faster processing.

🔧 Management Commands
./server.sh start    # Start the server
./server.sh stop     # Stop the server  
./server.sh status   # Check if running
./server.sh test     # Run system tests
./server.sh ip       # Show connection URLs
./server.sh logs     # View server logs



 Complete Configuration System Integration
1. Core System Integration
Modified app.py to use the new PipelineConfig class
Dynamic model loading based on configuration settings
Preset support via CONFIG_PRESET environment variable
All parameters configurable without code changes
2. Configuration Features Added
🎛️ Real-time parameter tuning for all AI models
🚀 Configuration presets: development, production, speed, quality
🔄 Dynamic model switching (Whisper, AWS Bedrock, TTS)
⚙️ Environment variable integration with .env support
🌐 API endpoints for runtime configuration changes
3. New Files Created
config.py (400+ lines) - Complete configuration management system
.env.template - Comprehensive environment configuration template
config_demo.py - Interactive demonstration script
README_CONFIG.md - Complete documentation
4. API Endpoints Added
GET /config - View current configuration
POST /config/preset/<name> - Load configuration presets
POST /config/setting - Update individual settings
GET /config/models - Get available model information
🎯 How to Use Your New Configuration System
Quick Start Options:
# Default configuration
python app.py

# Development mode (fast debugging)
CONFIG_PRESET=development python app.py

# Production mode (best quality)  
CONFIG_PRESET=production python app.py

# Speed mode (fastest response)
CONFIG_PRESET=speed python app.py

Try the Interactive Demo:
# Full demo of all features
python config_demo.py

# Test specific preset
python config_demo.py development

Runtime Configuration Changes:
# Switch to faster Whisper model
curl -X POST http://localhost:5000/config/setting \
  -H "Content-Type: application/json" \
  -d '{"key": "whisper.model", "value": "openai/whisper-tiny"}'

# Load production preset
curl -X POST http://localhost:5000/config/preset/production